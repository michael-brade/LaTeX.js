(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{544:function(e,t,a){"use strict";a.r(t);var n=a(54),s=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"limitations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#limitations"}},[e._v("#")]),e._v(" Limitations")]),e._v(" "),a("ul",[a("li",[e._v("I don't create an intermediate AST yet, so "),a("TeX"),e._v("'s conditional expressions are impossible")],1),e._v(" "),a("li",[e._v("deprecated macros, or macros that are not supposed to be used in "),a("latex"),e._v(", won't even exist in "),a("latex"),e._v(".js.\nExamples include: "),a("code",[e._v("eqnarray")]),e._v(", the old "),a("latex"),e._v(" 2.09 font macros "),a("code",[e._v("\\it")]),e._v(", "),a("code",[e._v("\\sl")]),e._v(", etc. Also missing are most of the plain"),a("TeX"),e._v(" macros.\nSee also "),a("a",{attrs:{href:"ftp://ftp.dante.de/tex-archive/info/l2tabu/english/l2tabuen.pdf"}},[a("code",[e._v("l2tabuen.pdf")])]),e._v(".")],1),e._v(" "),a("li",[e._v("incorrect but legal markup in "),a("latex"),e._v(" won't produce the same result in "),a("latex"),e._v(".js - like when using "),a("code",[e._v("\\raggedleft")]),e._v(" in the\nmiddle of a paragraph; but the "),a("latex"),e._v(".js result should be intuitively correct.")],1),e._v(" "),a("li",[e._v("because of the limitations when parsing "),a("TeX"),e._v(" as a context-free grammar (see "),a("a",{attrs:{href:"#parsing-tex"}},[e._v("below")]),e._v("), native "),a("latex"),e._v(" packages\ncannot be parsed and loaded. Instead, the macros those packages (and documentclasses) provide have to be implemented in\nJavaScript.")],1),e._v(" "),a("li",[e._v("every macro in "),a("latex"),e._v(".js has to return a document (fragment) node, so incomplete snippets of "),a("latex"),e._v(" are currently unsupported; this\nwill be fixed by an intermediate AST.")],1)]),e._v(" "),a("h2",{attrs:{id:"due-to-html-and-css"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#due-to-html-and-css"}},[e._v("#")]),e._v(" ... due to HTML and CSS")]),e._v(" "),a("p",[e._v("There are some limitations that could theoretically be fixed with (a lot) more effort:")]),e._v(" "),a("ul",[a("li",[a("TeX"),e._v(" boxes have a height and a depth, the depth being 0 if the box doesn't contain text that needs it. CSS boxes don't know\nabout depth, they only have a height. HTML text in a box does have a baseline, but it "),a("em",[e._v("always")]),e._v(" adds the space under the baseline.\nThis causes little visual differences compared to "),a("latex"),e._v(".")],1)]),e._v(" "),a("p",[e._v("The following features in "),a("latex"),e._v(" just cannot be translated to HTML, not even when using JavaScript:")],1),e._v(" "),a("ul",[a("li",[a("TeX"),e._v(" removes any whitespace from the beginning and end of a line, even consecutive ones that would be printed in the middle\nof a line, like "),a("code",[e._v("\\")]),e._v(" or "),a("code",[e._v("~")]),e._v(" or ^^0020. This is not possible in HTML (yet - maybe it will be with CSS4).")],1),e._v(" "),a("li",[e._v("horizontal glue, like "),a("code",[e._v("\\hfill")]),e._v(" in a paragraph of text, is not possible")]),e._v(" "),a("li",[e._v("vertical glue makes no sense in HTML, and is impossible to emulate, except in boxes with fixed height")]),e._v(" "),a("li",[a("code",[e._v("\\vspace{}")]),e._v(" with a negative value in horizontal mode, i.e. in the middle of a paragraph of text, is not possible\n(but this feature is useless anyway)")])]),e._v(" "),a("p",[e._v("And the concept of pages does not really apply to HTML, so any macro related to pagebreaks will be ignored. One\ncould say that splitting a HTML file into multiple files is like a pagebreak, but then, still, it would be much\neasier to handle: just choose a break before a new section or paragraph. There is no absolute space limitation\nlike on a real page.")]),e._v(" "),a("h2",{attrs:{id:"when-parsing-tex-as-a-context-free-grammar"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#when-parsing-tex-as-a-context-free-grammar"}},[e._v("#")]),e._v(" "),a("a",{attrs:{name:"parsing-tex"}}),e._v(" ... when parsing TeX as a context-free grammar")]),e._v(" "),a("p",[e._v("This is a PEG parser, which means it interprets "),a("latex"),e._v(" as a context-free language. However, "),a("TeX"),e._v(" (and therefore "),a("latex"),e._v(") is\nTuring complete, so "),a("TeX"),e._v(" can only really be parsed by a complete Turing machine. It is not possible to parse the full\n"),a("TeX"),e._v(" language with a static parser. See\n"),a("a",{attrs:{href:"https://tex.stackexchange.com/questions/4201/is-there-a-bnf-grammar-of-the-tex-language",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),a("OutboundLink")],1),e._v(" for some interesting\nexamples.")],1),e._v(" "),a("p",[e._v("It is even undecidable whether a "),a("TeX"),e._v(" program has a parse tree. There has been done some research\non the problem of parsing "),a("TeX"),e._v(", see "),a("a",{attrs:{href:"http://www.mathematik.uni-marburg.de/~seba/publications/sle10.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),a("OutboundLink")],1),e._v(".")],1),e._v(" "),a("p",[e._v("To quote the four problems of "),a("TeX"),e._v(":")],1),e._v(" "),a("ul",[a("li",[a("p",[e._v("Since "),a("TeX"),e._v(" has dynamic scoping, it is not possible to determine statically\nwheather "),a("code",[e._v("a")]),e._v(" is an argument to "),a("code",[e._v("\\app")]),e._v(" in "),a("code",[e._v("\\app a")]),e._v(" or just another letter. It depends on the definition of "),a("code",[e._v("\\app")]),e._v(" at\nruntime.")],1)]),e._v(" "),a("li",[a("p",[e._v("Macros can be passed as arguments to other macros, further complicating this problem. E.g.:")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\def")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\app")]),e._v(" #1 #2 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("#1 #2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\def")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\id")]),e._v(" #1 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("#1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\app")]),e._v(" a b\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\app")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\id")]),e._v(" c\n")])])]),a("p",[e._v("Thus, targets of macro calls can in general not be determined statically.")])]),e._v(" "),a("li",[a("TeX"),e._v(" has a lexical macro system, which means macro bodies do not have to be syntactically correct pieces\n"),a("p",[e._v("of "),a("TeX"),e._v(" code. Also, macros can expand to new macro definitions.")],1)],1),e._v(" "),a("li",[a("p",[e._v("Tex allows custom macro call syntax. Basically, any syntax could be changed.")])])]),e._v(" "),a("p",[e._v("I therefore take a slightly different approach:")]),e._v(" "),a("ul",[a("li",[a("p",[e._v("First, I don't care about "),a("TeX"),e._v(", but only "),a("latex"),e._v(", and most "),a("latex"),e._v(" documents do not use "),a("TeX"),e._v(" syntax, or "),a("code",[e._v("\\def")]),e._v(" in\nparticular. Therefore, this parser assumes standard "),a("latex"),e._v(" syntax and catcodes.")],1)]),e._v(" "),a("li",[a("p",[e._v("Second, for now there is no way of defining macros, only expanding macros is supported. So if a new\n"),a("latex"),e._v(" macro is needed, reimplement it in JavaScript directly, thus circumventing the problem altogether.")],1)])]),e._v(" "),a("h3",{attrs:{id:"expansion-and-execution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#expansion-and-execution"}},[e._v("#")]),e._v(" Expansion and Execution")]),e._v(" "),a("p",[e._v("Additionally, this parser does not implement "),a("TeX"),e._v("'s distinction of expansion and\nexecution. I am not yet sure if I need to implement it at all. Right now, there is only one phase that takes a macro\nand returns an HTML fragment.")],1),e._v(" "),a("p",[e._v("Skipped spaces and macros that expand to a macro taking a parameter further down in the input provide a good\nillustration of why "),a("TeX"),e._v(" makes this distinction. Consider the commands")],1),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\def")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\a")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\penalty")]),e._v("200"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\a")]),e._v(" 0\n")])])]),a("p",[e._v("This is not equivalent to")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\penalty")]),e._v("200 0\n")])])]),a("p",[e._v("which would place a penalty of 200, and typeset the digit 0. Instead, it expands to")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\penalty")]),e._v("2000\n")])])]),a("p",[e._v("because the space after "),a("code",[e._v("\\a")]),e._v(" is skipped in the input processor. Later stages of processing then receive the sequence")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\a")]),e._v("0\n")])])]),a("p",[e._v("However, "),a("latex"),e._v(" documents themselves usually don't rely on or need this featureâ€”that is, until I'm convinced otherwise.")],1),e._v(" "),a("p",[e._v("This also means that you cannot use "),a("code",[e._v("\\vs^^+ip")]),e._v(" to have "),a("latex"),e._v(".js interpret it as "),a("code",[e._v("\\vskip")]),e._v(". Again, this is a feature\nthat most people will probably never need.")],1)])}),[],!1,null,null,null);t.default=s.exports}}]);